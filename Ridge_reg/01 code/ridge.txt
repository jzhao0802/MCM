

##
## The purpose of this function is to try different optimization function, including optimr and optimrx; besides, also try to modify the functions to exclude 
## lambda (penalty factor) from the scope of optimization.


rm(list = ls())

#Load packages
library(doParallel)
library(dplyr)
library(xlsx)
# load in raw data
# root_path <- "D:/Project_Files3/EURO/MCM/BD"
root_path <- "../Data/RidgeReg"

destination_folder <- "Ridge Reg"  #update
rawdata_file_name <- "for_rr_stk_rt.csv"  #update
n_promo <- 5         # it is only for promotional variables  --  update
n_nonpromo <- 4      # it includes both the intercept and non-promo variables  -- update 
nonpromo_varnames <- c("log_trend", "pos", "neg")
y_position <- 2   # update according to rawdata_input below

# setwd(paste(root_path,destination_folder, sep="/"))

rawdata <- read.csv(paste0(root_path, rawdata_file_name), stringsAsFactors = FALSE)
cohort_column_name <- "final_segment"
sales_var_name <- "y1"

n_cohort <- n_distinct(rawdata[,cohort_column_name])

promo_varnames <- grep("_adj_stk_rt$", colnames(rawdata), value = TRUE)

# re-order columns
rawdata_input <- rawdata[ , c(cohort_column_name, sales_var_name, nonpromo_varnames, promo_varnames)] 


# cohort level priors
national_priors <- read.xlsx(paste(root_path, destination_folder, 'priorByCohort.xlsx', sep = '/'), stringsAsFactors = FALSE)

nat_priors<- grep('_adj_stk_rt$', national_priors[,'varNm']) %>% national_priors[ . , 'mu']

cohort_promo_priors <- matrix(nat_priors, nrow = n_cohort, ncol = n_promo, byrow = TRUE)
cohort_promo_priors <- cbind(c(1:n_cohort), cohort_promo_priors)
colnames(cohort_promo_priors) <- c(cohort_column_name, grep('_adj_stk_rt$', national_priors[,'varNm'], value = TRUE))


# define some functions... 

# the RidgeRSS is updated -- make shrinkage on intercept optinal, the default is NOT to shrink on intercept.
RidgeRSS <- function(    b_lambda  # b_lambda consists of penalty lambda, intercept, non-promo variables, promo variables. 
                         , X
                         , y
                         , b_prior   # b_prior includes intercept, non-promo variables, promo variables.
                         , intercept_shrinkage = FALSE
                         , weight=NULL 
){  
  
  if(is.null(weight)) {weight=rep(1,length(y))} # if no weight input, then evenly assign weight
  
  if(intercept_shrinkage){
    
    return( sum( weight*(y - X%*%(b_lambda[-1]))^2 ) + b_lambda[1] * sum(((b_lambda[-1])-b_prior)^2) )
    
  } else {
    
    return( sum( weight*(y - X%*%(b_lambda[-1]))^2 ) + b_lambda[1] * sum(((b_lambda[-c(1,2)])-b_prior[-1])^2) )  # removed penalty for intercept
    
  }
}

###
#@
nnridge <- function(   X
                       , y
                       , b_prior          # b_prior includes intercept, non-promo variables, promo variables.
                       , b_lambda_init    # b_lambda_init consists of initials for penalty lambda, intercept, non-promo variables, promo variables. 
                       , b_lambda_lower=-Inf
                       , b_lambda_upper=Inf
                       , intercept_shrinkage = FALSE
                       , weight=NULL
){
  
  p = length(b_prior)
  bfgsOptimConst = optim(par=b_lambda_init,  # put par in the first place according to the document
                         RidgeRSS, X=X, y=y, b_prior=b_prior, intercept_shrinkage= intercept_shrinkage, weight = weight,
                         lower=b_lambda_lower, upper=b_lambda_upper,
                         method = 'L-BFGS-B')
  par_est = bfgsOptimConst$par
  return(list(lambda=par_est[1], b=par_est[-1]))
  
}
#@@
nnridge2 <- function(   X
                       , y
                       , b_prior          # b_prior includes intercept, non-promo variables, promo variables.
                       , b_lambda_init    # b_lambda_init consists of initials for penalty lambda, intercept, non-promo variables, promo variables. 
                       , b_lambda_lower=-Inf
                       , b_lambda_upper=Inf
                       , intercept_shrinkage = FALSE
                       , weight=NULL
){
  
  p = length(b_prior)
  bfgsOptimConst = optimr(par=b_lambda_init,  # put par in the first place according to the document
                         RidgeRSS, X=X, y=y, b_prior=b_prior, intercept_shrinkage= intercept_shrinkage, weight = weight,
                         lower=b_lambda_lower, upper=b_lambda_upper,
                         method = 'L-BFGS-B')
  par_est = bfgsOptimConst$par
  return(list(lambda=par_est[1], b=par_est[-1]))
  
}


###

# test one cohort  ---changed for testing purpose.
One_Ridge_Reg <- function(tpdat, b_prior, lambda1_initial = 20, lambda1_lower_bound = 1, lambda1_upper_bound = 500, method = 'optim'){
  
  
  
  x1 = tpdat[,-c(1, y_position)]  # exclude ID and sales
  x1 = as.matrix(cbind(1, x1[ , "log_trend"], x1[ , "pos"], -x1[ , "neg"], x1[ , promo_varnames]))  # need manual setup...
  
  cc = tpdat[,1]
  
  y1 = tpdat[ , y_position]
  
  lambda1_init = lambda1_initial
  lambda1_lower = lambda1_lower_bound #lower bound
  lambda1_upper = lambda1_upper_bound  #upper bound
  if(method=='optim') {
    r1 = nnridge(X=x1
                   , y=y1
                   , b_prior=b_prior
                   , b_lambda_init=c(lambda1_init, b_prior)
                   , b_lambda_lower=c(lambda1_lower, rep(0, length(b_prior)))
                   , b_lambda_upper=c(lambda1_upper, rep(Inf, length(b_prior))))
                   
  } else if(method=="optimr"){
    
    r1 = nnridge2(X=x1
                   , y=y1
                   , b_prior=b_prior
                   , b_lambda_init=c(lambda1_init, b_prior)
                   , b_lambda_lower=c(lambda1_lower, rep(0, length(b_prior)))
                   , b_lambda_upper=c(lambda1_upper, rep(Inf, length(b_prior))))    
    
   }
  
  cat("Cohort ID = ", cc[1], "\n")
  cat("initial lambda: ", lambda1_init, "\n")
  cat("lambda lower bound: ", lambda1_lower, "\n")
  cat("lambda upper bound: ", lambda1_upper, "\n")
  cat("lambda selected: ", r1$lambda, "\n")  
  
  cat("estimated coefficients: ", r1$b, "\n")
  
  ypred = x1 %*% r1$b
  
  rsqr = 1- sum((y1 - ypred)^2)/sum((y1 - mean(y1))^2) # R-square
  
  cat("RSquare: ", rsqr, "\n")
  cat("Model for Cohort ID ", cc[1], " finished! \n")
  
  prediction = data.frame(cohort_id = cc[1], y=y1, ypred = ypred, stringsAsFactors = FALSE)
  
  return(list(cohort_id = cc[1], lambda = r1$lambda, beta = r1$b, rsquare = rsqr, pred = prediction))
  
}


### test 
cohort_id_test <- 3

tpdat_test <- rawdata_input[rawdata_input[ , cohort_column_name] == cohort_id_test,]

b_prior_test <- cohort_promo_priors[ cohort_promo_priors[,cohort_column_name]==cohort_id_test, promo_varnames]  
b_prior_test <- c(rep(0,n_nonpromo), b_prior_test)
names(b_prior_test) <- NULL

s1 <- One_Ridge_Reg(tpdat_test, b_prior_test, lambda1_initial = 20)    
s1b <- One_Ridge_Reg(tpdat_test, b_prior_test, method = 'optimr')



#######    write another version of function without optimizing the lambda1

RidgeRSS2 <- function(     b      # b consists of intercept, non-promo variables, promo variables. To be optimized on. No penalty lambda
                         , X
                         , y
                         
                         , b_prior   # b_prior includes intercept, non-promo variables, promo variables.
                         , lambda   # lambda for penalty
                         , intercept_shrinkage = FALSE
                         , weight=NULL 
){  
  
  if(is.null(weight)) {weight=rep(1,length(y))} # if no weight input, then evenly assign weight
  
  if(intercept_shrinkage){
    
    return( sum( weight*(y - X %*% b)^2 ) + lambda * sum((b-b_prior)^2) )
    
  } else {
    
    return( sum( weight*(y - X %*% b)^2 ) + lambda * sum((b[-1]-b_prior[-1])^2) )  # removed penalty for intercept
    
  }
}

nnridge3 <- function(    X
                       , y
                       , b_prior          # b_prior includes intercept, non-promo variables, promo variables.
                       , b_init    # b_lambda_init consists of initials for intercept, non-promo variables, promo variables. No penalty lambda 
                       , lambda_specified    # specified lambda
                       , b_lower=-Inf
                       , b_upper=Inf
                       , intercept_shrinkage = FALSE
                       , weight=NULL
){
  
  p = length(b_prior)
  bfgsOptimConst = optim(par=b_init,  # put par in the first place according to the document
                         RidgeRSS2, X=X, y=y, b_prior=b_prior, lambda = lambda_specified, intercept_shrinkage= intercept_shrinkage, weight = weight,
                         lower=b_lower, upper=b_upper,
                         method = 'L-BFGS-B')
  par_est = bfgsOptimConst$par
  return(list(lambda= lambda_specified, b=par_est))
  
}

One_Ridge_Reg2 <- function(tpdat, b_prior, lambda_specified = 20
                           # , lambda1_lower_bound = 1
                           # , lambda1_upper_bound = 500
                           # , method = 'optim'
                           ){
  
  
  
  x1 = tpdat[,-c(1, y_position)]  # exclude ID and sales
  x1 = as.matrix(cbind(1, x1[ , "log_trend"], x1[ , "pos"], -x1[ , "neg"], x1[ , promo_varnames]))  # need manual setup...
  
  cc = tpdat[,1]
  
  y1 = tpdat[ , y_position]
  
  # lambda1_init = lambda1_initial
  # lambda1_lower = lambda1_lower_bound #lower bound
  # lambda1_upper = lambda1_upper_bound  #upper bound

    r1 = nnridge3(X=x1
                 , y=y1
                 , b_prior=b_prior
                 , b_init= b_prior
                 , lambda_specified = lambda_specified
                 , b_lower=c(rep(0, length(b_prior)))
                 , b_upper=c(rep(Inf, length(b_prior))))
 
  
  cat("Cohort ID = ", cc[1], "\n")
  # cat("initial lambda: ", lambda1_init, "\n")
  # cat("lambda lower bound: ", lambda1_lower, "\n")
  # cat("lambda upper bound: ", lambda1_upper, "\n")
  cat("lambda specified: ", r1$lambda, "\n")  
  
  cat("estimated coefficients: ", r1$b, "\n")
  
  ypred = x1 %*% r1$b
  
  rsqr = 1- sum((y1 - ypred)^2)/sum((y1 - mean(y1))^2) # R-square
  
  cat("RSquare: ", rsqr, "\n")
  cat("Model for Cohort ID ", cc[1], " finished! \n")
  
  prediction = data.frame(cohort_id = cc[1], y=y1, ypred = ypred, stringsAsFactors = FALSE)
  
  return(list(cohort_id = cc[1], lambda = r1$lambda, beta = r1$b, rsquare = rsqr, pred = prediction))
  

}

### test 
cohort_id_test <- 3

tpdat_test <- rawdata_input[rawdata_input[ , cohort_column_name] == cohort_id_test,]

b_prior_test <- cohort_promo_priors[ cohort_promo_priors[,cohort_column_name]==cohort_id_test, promo_varnames]  
b_prior_test <- c(rep(0,n_nonpromo), b_prior_test)
names(b_prior_test) <- NULL

s1 <- One_Ridge_Reg2(tpdat_test, b_prior_test, lambda_specified = 1)  #-- it is minor difference as above

